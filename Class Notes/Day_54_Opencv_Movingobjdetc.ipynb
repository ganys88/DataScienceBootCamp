{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Moving Object Detection"
      ],
      "metadata": {
        "id": "XW3WKGZ9uHca"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcFJU1imtDd8"
      },
      "outputs": [],
      "source": [
        "import cv2     #image\n",
        "import time    #delay\n",
        "import imutils #resize\n",
        "\n",
        "#cam = cv2.VideoCapture(\"people-detection.mp4\")\n",
        "cam = cv2.VideoCapture(0) #cam id\n",
        "time.sleep(1)\n",
        "\n",
        "firstFrame=None\n",
        "area = 500\n",
        "count=0\n",
        "while True:\n",
        "    count = count+1\n",
        "    _,img = cam.read()      #read frame from camera\n",
        "    text  = \"Normal\"\n",
        "    img   = imutils.resize(img, width=500) #resize\n",
        "\n",
        "    grayImg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #color 2 Gray scale image\n",
        "\n",
        "    gaussianImg = cv2.GaussianBlur(grayImg, (21, 21), 0) #smoothened\n",
        "\n",
        "    if firstFrame is None:\n",
        "            firstFrame = gaussianImg #capturing 1st frame on 1st iteration\n",
        "            continue\n",
        "\n",
        "    imgDiff = cv2.absdiff(firstFrame, gaussianImg) #absolute diff b/w 1st nd current frame\n",
        "\n",
        "    threshImg = cv2.threshold(imgDiff, 25, 255, cv2.THRESH_BINARY)[1] # threshold convert 2 binary\n",
        "\n",
        "    threshImg = cv2.dilate(threshImg, None, iterations=2)\n",
        "\n",
        "    cnts = cv2.findContours(threshImg.copy(), cv2.RETR_EXTERNAL,\n",
        "            cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    cnts = imutils.grab_contours(cnts)\n",
        "    for c in cnts:\n",
        "            if cv2.contourArea(c) < area:\n",
        "                    continue\n",
        "            (x, y, w, h) = cv2.boundingRect(c)\n",
        "            cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "            text = \"Moving Object detected\"\n",
        "\n",
        "    cv2.putText(img, text, (10, 20),\n",
        "            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "    cv2.imwrite(\"img/\"+str(count)+\"demo.jpg\",img)\n",
        "    cv2.imshow(\"cameraFeed\",img)\n",
        "    key = cv2.waitKey(1) & 0xFF\n",
        "    if key == ord(\"q\"):\n",
        "        break\n",
        "\n",
        "cam.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Webcam Detection**"
      ],
      "metadata": {
        "id": "sQ22UadZuYgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
        "\n",
        "\n",
        "while(1):\n",
        "    ret,frame = cap.read()\n",
        "\n",
        "    fgmask =fgbg.apply(frame)\n",
        "\n",
        "    cv2.imshow('Webcam', frame)\n",
        "    cv2.imshow('fgmask', fgmask)\n",
        "\n",
        "    if cv2.waitKey(1) == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "Wag0hxLeuhOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Image Detection**"
      ],
      "metadata": {
        "id": "9BPjUph8uqia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "cap = cv2.VideoCapture('people-detection.mp4')\n",
        "fgbg = cv2.createBackgroundSubtractorMOG2()  #forgroundbackground\n",
        "\n",
        "\n",
        "while(1):\n",
        "    ret,frame = cap.read()\n",
        "\n",
        "    fgmask =fgbg.apply(frame)\n",
        "\n",
        "    cv2.imshow('fgmask', fgmask)\n",
        "    cv2.imshow('frame', frame)\n",
        "\n",
        "\n",
        "    k = cv2.waitKey(30) & 0xff\n",
        "    if k == 27:\n",
        "        break\n",
        "\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "9lwL4vKhu2Uy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}